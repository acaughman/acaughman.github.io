[
  {
    "path": "posts/2022-02-10-post1/",
    "title": "Predicting Palmetto Species using Binary Logistic Regression",
    "description": {},
    "author": [
      {
        "name": "Allie Caughman",
        "url": {}
      }
    ],
    "date": "2022-02-10",
    "categories": [],
    "contents": "\r\nOverview\r\nThis report will preform logistic regression to predict which of two species of palmetto, Serenoa repens and Sabal etonia, a specific record is. Data was collected from south-central Flordia every 5 years form 1981 to 2017. Data used in these models include:\r\nheight: The maximum height recorded between 1981 and 2017 in centimeters\r\nlength: The widest length of the canopy between 1981 and 2017 in centimeters\r\nwidth: widest width of the canopy perpendicular to length between 1981 and 2017 in centimeters\r\ngreen_lvs: total count of green leaves from 1981 and 2017\r\nI hope to answer how well palmetto species can be predicted based on these four variables.\r\n\r\n\r\nhide\r\n\r\n palmetto = read_csv(here(\"data\", \"palmetto.csv\")) %>% \r\n  mutate(species = as.factor(species))  # turn species into a factor\r\n\r\n\r\n\r\nExploratory Graphs\r\n\r\n\r\nhide\r\n\r\npal_p = palmetto %>% \r\n  mutate(species = case_when(\r\n    species == '1' ~ \"Serenoa repens\",\r\n    species == '2' ~ \"Sabal etonia\",\r\n  )) #mutate species names for plots to have actual names and not numerics\r\n\r\np1 = ggplot(pal_p, aes(species, width)) + #plot species versus canopy width\r\n  theme_bw() +\r\n  geom_boxplot(aes(color = species)) + #add boxplot\r\n  labs(x = \"Species\",\r\n       y = \"Canopy Width (cm)\", \r\n       color = \"Species\") #axis labels\r\n\r\np2 = ggplot(pal_p, aes(height, length)) + #plot canopy length versus height\r\n  theme_bw() +\r\n  geom_point(aes(color = species)) + #add scatter plot\r\n  theme(legend.position = \"none\") + #remove legend\r\n  labs(x = \"Plant Height (cm)\",\r\n       y = \"Canopy Length (cm)\") #axis labels\r\n\r\np3 = ggplot(pal_p, aes(species, green_lvs)) + #plot species versus green leaves\r\n  theme_bw() +\r\n  geom_boxplot(aes(color = species)) + #add boxplot\r\n  labs(x = \"Species\",\r\n       y = \"Number of Green Leaves\", \r\n       color = \"Species\") #axis labels\r\n\r\n(p1 + p3) / p2 + plot_layout(guides = \"collect\") + plot_annotation(tag_levels = 'A') #combine plots\r\n\r\n\r\n\r\n\r\nFigure 1: Figure 1. Exploratory visualizations for characteristics of different palmetto species. A) Sabal etonia has slightly higher canopy widths than Serenoa repens. B) Sabal etonia has less green leaves than Serenoa repens. C) There is a positive correlation between plant height and canopy length. Sabal etonia appears to ahve longer canopy lengths than Serenoa repens.\r\n\r\n\r\n\r\nBased on these exploratory visualizations, canopy width does not seem to different much between species and may not be a good predictor. Green leaves and canopy length, however, seem to have different patterns between species. Plant height also has less differences between species and may or may not be useful as a predictor.\r\nBinary Logistic Regression\r\nFirst, I define the formulas and the models.\r\n\r\n\r\nhide\r\n\r\nf1 = species ~ height + length + width + green_lvs #model 1 formula\r\nm1 = glm(f1, data = palmetto, family = \"binomial\") #model 1\r\n\r\nf2 = species ~ height + width + green_lvs #model 2 formula\r\nm2 = glm(f2, data = palmetto, family = \"binomial\") #model 2\r\n\r\npred_acc <- function(x, y) { #prediction accuracy function\r\n  accurate <- ifelse(x == y, 1, 0)\r\n  return(mean(accurate, na.rm = TRUE))\r\n}\r\n\r\n\r\n\r\nThen, I preform ten-fold cross validation using prediction accuracy as the metric in order to determine which model is the best. I also compare AICc.\r\n\r\n\r\nhide\r\n\r\n#cross validation\r\nset.seed(42)  \r\n\r\nn_folds = 10 \r\nfolds = rep(1:n_folds, length.out = nrow(palmetto)) #create a folds vector\r\npal_kfold = palmetto %>% #assign each palmetto value to a fold\r\n  mutate(fold = sample(folds, size = n(), replace = FALSE))\r\n\r\nresults_df <- data.frame() #holding dataframe\r\n\r\n##loop through the folds\r\nfor(i in 1:n_folds) {\r\n  #get correct testing and training data for each fold\r\n  kfold_test <- pal_kfold %>%\r\n    filter(fold == i)\r\n  kfold_train <- pal_kfold %>%\r\n    filter(fold != i)\r\n  \r\n  #run the models on the training data\r\n  kfold_m1 <- glm(f1, data = kfold_train, family = 'binomial')\r\n  kfold_m2 <- glm(f2, data = kfold_train, family = 'binomial')\r\n  \r\n  #predict the test values \r\n  kfold_pred <- kfold_test %>%\r\n    mutate(m1 = predict(kfold_m1, kfold_test, type = 'response'),\r\n           m2 = predict(kfold_m2, ., type = 'response')) %>%\r\n    mutate(pred1 = ifelse(m1 > 0.50, '2', '1'),\r\n           pred2 = ifelse(m2 > 0.50, '2', '1'))\r\n \r\n  #calculate the accuracy\r\n   kfold_accuracy <- kfold_pred %>%\r\n    summarize(m1_acc = pred_acc(species, pred1),\r\n              m2_acc = pred_acc(species, pred2))\r\n  \r\n   #append results to the holding dataframe\r\n  results_df <- bind_rows(results_df, kfold_accuracy)\r\n}\r\n\r\nresults_sum = results_df %>% #get the mean accuracy for each model\r\n  summarize(model1_acc = mean(m1_acc),\r\n            model2_acc = mean(m2_acc))\r\n\r\nAIC = AICcmodavg::aictab(list(m1, m2)) #calculate AIC for each model\r\n\r\n\r\n\r\nModel 1 has an accuracy of 0.917, which is higher than Model 2, which has an accuracy of 0.899. Therefore, Model 1 is the better model. The AICc values also agree with this with Model 1 (AIC = 5194.57) having a much lower AIC than Model 2 (AICc = 5987.48). Canopy length is an important predictor to retain in the model.\r\nResults\r\n\r\n\r\nhide\r\n\r\nfinal_model = glm(f1, data = palmetto, family = \"binomial\") #train best model on all data\r\n\r\nmodel_results = tidy(final_model) %>% #use broom to get tidy model results\r\n  kbl(digits = 3, caption = \"Table 1. Results of binary logistic regression prediction species from canopy height, length, and width, and number of green leaves. All predictors were signficant. There was a postiive correltation between length and width and being Sabal etonia and negative correlation for green leaves and canopy height.\", col.names = c(\"Term\", \"Coefficient\", \"Standard Error\", \"Z-value\", \"p-value\")) %>% #create table\r\n  kable_minimal() #change table theme\r\n\r\nmodel_results #print table\r\n\r\n\r\n\r\nTable 1: Table 1. Results of binary logistic regression prediction species from canopy height, length, and width, and number of green leaves. All predictors were signficant. There was a postiive correltation between length and width and being Sabal etonia and negative correlation for green leaves and canopy height.\r\n\r\n\r\nTerm\r\n\r\n\r\nCoefficient\r\n\r\n\r\nStandard Error\r\n\r\n\r\nZ-value\r\n\r\n\r\np-value\r\n\r\n\r\n(Intercept)\r\n\r\n\r\n3.227\r\n\r\n\r\n0.142\r\n\r\n\r\n22.712\r\n\r\n\r\n0\r\n\r\n\r\nheight\r\n\r\n\r\n-0.029\r\n\r\n\r\n0.002\r\n\r\n\r\n-12.670\r\n\r\n\r\n0\r\n\r\n\r\nlength\r\n\r\n\r\n0.046\r\n\r\n\r\n0.002\r\n\r\n\r\n24.556\r\n\r\n\r\n0\r\n\r\n\r\nwidth\r\n\r\n\r\n0.039\r\n\r\n\r\n0.002\r\n\r\n\r\n18.782\r\n\r\n\r\n0\r\n\r\n\r\ngreen_lvs\r\n\r\n\r\n-1.908\r\n\r\n\r\n0.039\r\n\r\n\r\n-49.107\r\n\r\n\r\n0\r\n\r\n\r\n\r\n\r\nhide\r\n\r\nmodel_fitted <- final_model %>%\r\n  broom::augment(type.predict = \"response\") %>% #get probabilities\r\n  select(species, .fitted) %>% \r\n  mutate(prediction = case_when(\r\n    .fitted > .5 ~ 2,\r\n    .fitted < .5 ~ 1\r\n  )) %>% #use probabilities to determine species prediction\r\n  mutate(correct = ifelse(species == prediction, 0, 1)) %>%  #determine how many predictions were correct\r\n  mutate(species = case_when(\r\n    species == '1' ~ \"Serenoa repens\",\r\n    species == '2' ~ \"Sabal etonia\",\r\n  )) #mutate species names for plots to have actual names and not numerics\r\n\r\nmodel_sum = model_fitted %>% \r\n  group_by(species) %>% #group by species\r\n  summarize(num_incorrect = sum(correct), #get number incorrect with sum\r\n            accuracy = 1 - mean(correct)) %>% #get % accurate with 1 - mean\r\n  kbl(digits = 2, caption = \"Table 2. Number of incorrect predictions and the percent of predictions that were correct for each palmetto species.\", col.names = c(\"Species\", \"Number Incorrectly Classified\", \"% Correctly Classified\")) %>% #create table\r\n  kable_minimal() #change table theme\r\n\r\nmodel_sum #print table\r\n\r\n\r\n\r\nTable 2: Table 2. Number of incorrect predictions and the percent of predictions that were correct for each palmetto species.\r\n\r\n\r\nSpecies\r\n\r\n\r\nNumber Incorrectly Classified\r\n\r\n\r\n% Correctly Classified\r\n\r\n\r\nSabal etonia\r\n\r\n\r\n454\r\n\r\n\r\n0.93\r\n\r\n\r\nSerenoa repens\r\n\r\n\r\n564\r\n\r\n\r\n0.91\r\n\r\n\r\nConclusion\r\nThe model preforms well at predicted both species of palmetto, although it preforms slightly better on Sabal etonia compared to Sernoa repens. More green green leaves and a taller canopy, but lower canopy height and widths are associated with being Sernoa repens.\r\nCitation\r\nAbrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-02-10-post1/post1_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-02-10T15:57:12-08:00",
    "input_file": {}
  }
]
